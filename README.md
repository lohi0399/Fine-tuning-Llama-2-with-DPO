# Fine-tuning-Llama-2-with-DPO
DPO pipeline for the creation of StackLlaMa 2: a Stack exchange llama-v2-7b model
